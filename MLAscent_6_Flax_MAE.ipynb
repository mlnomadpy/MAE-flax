{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOuHVmwW8FuF4JTLD+LXVRr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywolfmo/MAE-flax/blob/master/MLAscent_6_Flax_MAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Ascnet 6: MAE for SSL"
      ],
      "metadata": {
        "id": "KD1Kkil6Irx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Taha Bouhsine - ML GDE\n",
        "\n",
        "Contact: @tahabsn - contact@tahabouhsine.com"
      ],
      "metadata": {
        "id": "q27-OpSRIxVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVVp9XW0tw_X",
        "outputId": "f61e8d56-d509-4638-ca2a-3f311218c27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Epoch 1, Average Loss: 0.0271\n",
            "Epoch 2, Average Loss: 0.0126\n",
            "Epoch 3, Average Loss: 0.0105\n",
            "Epoch 4, Average Loss: 0.0096\n",
            "Epoch 5, Average Loss: 0.0092\n",
            "Epoch 6, Average Loss: 0.0088\n",
            "Epoch 7, Average Loss: 0.0086\n",
            "Epoch 8, Average Loss: 0.0085\n",
            "Epoch 9, Average Loss: 0.0082\n",
            "Epoch 10, Average Loss: 0.0082\n",
            "Epoch 11, Average Loss: 0.0080\n",
            "Epoch 12, Average Loss: 0.0079\n",
            "Epoch 13, Average Loss: 0.0078\n",
            "Epoch 14, Average Loss: 0.0078\n",
            "Epoch 15, Average Loss: 0.0077\n",
            "Epoch 16, Average Loss: 0.0076\n",
            "Epoch 17, Average Loss: 0.0076\n",
            "Epoch 18, Average Loss: 0.0075\n",
            "Epoch 19, Average Loss: 0.0075\n",
            "Epoch 20, Average Loss: 0.0074\n",
            "Epoch 21, Average Loss: 0.0074\n",
            "Epoch 22, Average Loss: 0.0074\n",
            "Epoch 23, Average Loss: 0.0073\n",
            "Epoch 24, Average Loss: 0.0073\n",
            "Epoch 25, Average Loss: 0.0073\n",
            "Epoch 26, Average Loss: 0.0072\n",
            "Epoch 27, Average Loss: 0.0072\n",
            "Epoch 28, Average Loss: 0.0071\n",
            "Epoch 29, Average Loss: 0.0071\n",
            "Epoch 30, Average Loss: 0.0071\n",
            "Epoch 31, Average Loss: 0.0070\n",
            "Epoch 32, Average Loss: 0.0070\n",
            "Epoch 33, Average Loss: 0.0070\n",
            "Epoch 34, Average Loss: 0.0070\n",
            "Epoch 35, Average Loss: 0.0070\n",
            "Epoch 36, Average Loss: 0.0069\n",
            "Epoch 37, Average Loss: 0.0069\n",
            "Epoch 38, Average Loss: 0.0069\n",
            "Epoch 39, Average Loss: 0.0068\n",
            "Epoch 40, Average Loss: 0.0068\n",
            "Epoch 41, Average Loss: 0.0068\n",
            "Epoch 42, Average Loss: 0.0068\n",
            "Epoch 43, Average Loss: 0.0068\n",
            "Epoch 44, Average Loss: 0.0068\n",
            "Epoch 45, Average Loss: 0.0068\n",
            "Epoch 46, Average Loss: 0.0068\n",
            "Epoch 47, Average Loss: 0.0068\n",
            "Epoch 48, Average Loss: 0.0068\n",
            "Epoch 49, Average Loss: 0.0067\n",
            "Epoch 50, Average Loss: 0.0067\n",
            "Epoch 51, Average Loss: 0.0067\n",
            "Epoch 52, Average Loss: 0.0067\n",
            "Epoch 53, Average Loss: 0.0067\n",
            "Epoch 54, Average Loss: 0.0067\n",
            "Epoch 55, Average Loss: 0.0067\n",
            "Epoch 56, Average Loss: 0.0067\n",
            "Epoch 57, Average Loss: 0.0066\n",
            "Epoch 58, Average Loss: 0.0066\n",
            "Epoch 59, Average Loss: 0.0066\n",
            "Epoch 60, Average Loss: 0.0067\n",
            "Epoch 61, Average Loss: 0.0066\n",
            "Epoch 62, Average Loss: 0.0066\n",
            "Epoch 63, Average Loss: 0.0066\n",
            "Epoch 64, Average Loss: 0.0066\n",
            "Epoch 65, Average Loss: 0.0066\n",
            "Epoch 66, Average Loss: 0.0066\n",
            "Epoch 67, Average Loss: 0.0066\n",
            "Epoch 68, Average Loss: 0.0066\n",
            "Epoch 69, Average Loss: 0.0065\n",
            "Epoch 70, Average Loss: 0.0065\n",
            "Epoch 71, Average Loss: 0.0065\n",
            "Epoch 72, Average Loss: 0.0065\n",
            "Epoch 73, Average Loss: 0.0065\n",
            "Epoch 74, Average Loss: 0.0065\n",
            "Epoch 75, Average Loss: 0.0065\n",
            "Epoch 76, Average Loss: 0.0065\n",
            "Epoch 77, Average Loss: 0.0065\n",
            "Epoch 78, Average Loss: 0.0065\n",
            "Epoch 79, Average Loss: 0.0065\n",
            "Epoch 80, Average Loss: 0.0065\n",
            "Epoch 81, Average Loss: 0.0065\n",
            "Epoch 82, Average Loss: 0.0064\n",
            "Epoch 83, Average Loss: 0.0065\n",
            "Epoch 84, Average Loss: 0.0065\n",
            "Epoch 85, Average Loss: 0.0064\n",
            "Epoch 86, Average Loss: 0.0064\n",
            "Epoch 87, Average Loss: 0.0065\n",
            "Epoch 88, Average Loss: 0.0064\n",
            "Epoch 89, Average Loss: 0.0065\n",
            "Epoch 90, Average Loss: 0.0064\n",
            "Epoch 91, Average Loss: 0.0064\n",
            "Epoch 92, Average Loss: 0.0064\n",
            "Epoch 93, Average Loss: 0.0064\n",
            "Epoch 94, Average Loss: 0.0064\n",
            "Epoch 95, Average Loss: 0.0064\n",
            "Epoch 96, Average Loss: 0.0064\n",
            "Epoch 97, Average Loss: 0.0064\n",
            "Epoch 98, Average Loss: 0.0064\n",
            "Epoch 99, Average Loss: 0.0064\n",
            "Epoch 100, Average Loss: 0.0064\n",
            "Pretraining complete!\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    hidden_dim: int\n",
        "    out_dim: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(features=self.hidden_dim)(x)\n",
        "        x = nn.gelu(x)\n",
        "        x = nn.Dense(features=self.out_dim)(x)\n",
        "        return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    num_heads: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        d_model = x.shape[-1]\n",
        "        d_head = d_model // self.num_heads\n",
        "\n",
        "        qkv = nn.Dense(features=d_model * 3, use_bias=False)(x)\n",
        "        qkv = qkv.reshape(x.shape[0], -1, 3, self.num_heads, d_head)\n",
        "        qkv = jnp.transpose(qkv, (2, 0, 3, 1, 4))\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attention = jnp.matmul(q, jnp.swapaxes(k, -1, -2)) / jnp.sqrt(d_head)\n",
        "        attention = nn.softmax(attention, axis=-1)\n",
        "\n",
        "        y = jnp.matmul(attention, v)\n",
        "        y = jnp.transpose(y, (0, 2, 1, 3))\n",
        "        y = y.reshape(x.shape[0], -1, d_model)\n",
        "\n",
        "        y = nn.Dense(features=d_model)(y)\n",
        "        return y\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    num_heads: int\n",
        "    mlp_dim: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        y = nn.LayerNorm()(x)\n",
        "        y = Attention(num_heads=self.num_heads)(y)\n",
        "        x = x + y\n",
        "\n",
        "        y = nn.LayerNorm()(x)\n",
        "        y = MLP(hidden_dim=self.mlp_dim, out_dim=x.shape[-1])(y)\n",
        "        return x + y\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    patch_size: int = 4\n",
        "    hidden_dim: int = 256\n",
        "    num_heads: int = 8\n",
        "    num_layers: int = 6\n",
        "    mlp_dim: int = 512\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, train=True):\n",
        "        b, n, c = x.shape\n",
        "\n",
        "        # Add position embedding\n",
        "        pos_embedding = self.param('pos_embedding', nn.initializers.normal(stddev=0.02), (1, n, self.hidden_dim))\n",
        "        x = nn.Dense(features=self.hidden_dim)(x)\n",
        "        x = x + pos_embedding\n",
        "\n",
        "        # Transformer blocks\n",
        "        for _ in range(self.num_layers):\n",
        "            x = TransformerBlock(num_heads=self.num_heads, mlp_dim=self.mlp_dim)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MAEEncoder(nn.Module):\n",
        "    patch_size: int = 4\n",
        "    hidden_dim: int = 256\n",
        "    num_heads: int = 8\n",
        "    num_layers: int = 6\n",
        "    mlp_dim: int = 512\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, mask):\n",
        "        # x is already patchified\n",
        "        b, n, c = x.shape\n",
        "\n",
        "        # Add position embedding to unmasked tokens\n",
        "        pos_embedding = self.param('pos_embedding', nn.initializers.normal(stddev=0.02), (1, n, self.hidden_dim))\n",
        "        x = nn.Dense(features=self.hidden_dim)(x)\n",
        "        x = x + pos_embedding\n",
        "\n",
        "        # Apply mask\n",
        "        x = x * mask[:, :, None]\n",
        "\n",
        "        # Transformer blocks\n",
        "        vit = ViT(patch_size=self.patch_size, hidden_dim=self.hidden_dim,\n",
        "                  num_heads=self.num_heads, num_layers=self.num_layers, mlp_dim=self.mlp_dim)\n",
        "        x = vit(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MAEDecoder(nn.Module):\n",
        "    patch_size: int = 4\n",
        "    hidden_dim: int = 128\n",
        "    num_heads: int = 4\n",
        "    num_layers: int = 2\n",
        "    mlp_dim: int = 256\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, mask):\n",
        "        b, n = mask.shape\n",
        "\n",
        "        # Add position embedding\n",
        "        pos_embedding = self.param('pos_embedding', nn.initializers.normal(stddev=0.02), (1, n, self.hidden_dim))\n",
        "        x = nn.Dense(features=self.hidden_dim)(x)\n",
        "\n",
        "        # Add mask tokens\n",
        "        mask_token = self.param('mask_token', nn.initializers.normal(stddev=0.02), (1, 1, self.hidden_dim))\n",
        "        mask_tokens = jnp.broadcast_to(mask_token, (b, n, self.hidden_dim))\n",
        "        x = x * mask[:, :, None] + mask_tokens * (1 - mask[:, :, None])\n",
        "\n",
        "        x = x + pos_embedding\n",
        "\n",
        "        # Transformer blocks\n",
        "        vit = ViT(patch_size=self.patch_size, hidden_dim=self.hidden_dim,\n",
        "                  num_heads=self.num_heads, num_layers=self.num_layers, mlp_dim=self.mlp_dim)\n",
        "        x = vit(x)\n",
        "\n",
        "        # Project to patch dimension\n",
        "        x = nn.Dense(features=self.patch_size**2 * 3)(x)\n",
        "        x = nn.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MaskedAutoencoder(nn.Module):\n",
        "    encoder: nn.Module\n",
        "    decoder: nn.Module\n",
        "    mask_ratio: float = 0.75\n",
        "    patch_size: int = 4\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, img, train=True, rngs=None):\n",
        "        # Patchify the image (for CIFAR-10, we'll use 4x4 patches)\n",
        "        patches = self.patchify(img)\n",
        "        batch, num_patches, _ = patches.shape\n",
        "\n",
        "        # Create mask\n",
        "        mask = self.create_mask(rngs['mask'] if rngs is not None else None, batch, num_patches)\n",
        "\n",
        "        # Encode\n",
        "        encoded = self.encoder(patches, mask)\n",
        "\n",
        "        # Decode\n",
        "        decoded = self.decoder(encoded, mask)\n",
        "\n",
        "        # Unpatchify the output\n",
        "        reconstructed = self.unpatchify(decoded, img.shape)\n",
        "\n",
        "        return reconstructed, mask\n",
        "\n",
        "    def patchify(self, imgs):\n",
        "        batch_size, height, width, channels = imgs.shape\n",
        "        num_patches = (height // self.patch_size) * (width // self.patch_size)\n",
        "        patches = imgs.reshape(batch_size, height // self.patch_size, self.patch_size, width // self.patch_size, self.patch_size, channels)\n",
        "        patches = patches.transpose(0, 1, 3, 2, 4, 5)\n",
        "        patches = patches.reshape(batch_size, num_patches, -1)\n",
        "        return patches\n",
        "\n",
        "    def unpatchify(self, patches, original_shape):\n",
        "        batch_size, height, width, channels = original_shape\n",
        "        patches = patches.reshape(batch_size, height // self.patch_size, width // self.patch_size, self.patch_size, self.patch_size, channels)\n",
        "        imgs = patches.transpose(0, 1, 3, 2, 4, 5)\n",
        "        imgs = imgs.reshape(batch_size, height, width, channels)\n",
        "        return imgs\n",
        "\n",
        "    def create_mask(self, rng, batch, num_patches):\n",
        "        if rng is None:\n",
        "            rng = self.make_rng('mask')\n",
        "        noise = jax.random.uniform(rng, (batch, num_patches))\n",
        "        mask = jnp.where(noise > self.mask_ratio, 1., 0.)\n",
        "        return mask\n",
        "\n",
        "@jax.jit\n",
        "def train_step(state, batch, rng):\n",
        "    rng, new_rng = jax.random.split(rng)\n",
        "    def loss_fn(params):\n",
        "        reconstructed, mask = state.apply_fn({'params': params}, batch, train=True, rngs={'mask': rng})\n",
        "        loss = optax.l2_loss(reconstructed, batch).mean()\n",
        "        return loss\n",
        "\n",
        "    grad_fn = jax.value_and_grad(loss_fn)\n",
        "    loss, grads = grad_fn(state.params)\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    return state, loss, new_rng\n",
        "\n",
        "\n",
        "\n",
        "def load_cifar10():\n",
        "    (x_train, _), (x_test, _) = cifar10.load_data()\n",
        "    x_train = x_train.astype(np.float32) / 255.\n",
        "    x_test = x_test.astype(np.float32) / 255.\n",
        "    return x_train, x_test\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_reconstructions(original, reconstructed, mask, epoch):\n",
        "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "    for i in range(4):\n",
        "        # Original image\n",
        "        axs[0, i].imshow(original[i])\n",
        "        axs[0, i].set_title(f\"Original {i+1}\")\n",
        "        axs[0, i].axis('off')\n",
        "\n",
        "        # Reconstructed image\n",
        "        axs[1, i].imshow(reconstructed[i])\n",
        "        axs[1, i].set_title(f\"Reconstructed {i+1}\")\n",
        "        axs[1, i].axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"reconstruction_epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_reconstruction(state, test_images, rng):\n",
        "    reconstructed, mask = state.apply_fn({'params': state.params}, test_images, train=False, rngs={'mask': rng})\n",
        "    return reconstructed, mask\n",
        "\n",
        "def main():\n",
        "    x_train, x_test = load_cifar10()\n",
        "\n",
        "    encoder = MAEEncoder()\n",
        "    decoder = MAEDecoder()\n",
        "    mae = MaskedAutoencoder(encoder=encoder, decoder=decoder)\n",
        "\n",
        "    rng = jax.random.PRNGKey(0)\n",
        "    rng, init_rng = jax.random.split(rng)\n",
        "    params = mae.init({'params': init_rng, 'mask': init_rng}, jnp.ones((1, 32, 32, 3)))['params']\n",
        "\n",
        "    tx = optax.adam(learning_rate=1e-3)\n",
        "    state = train_state.TrainState.create(apply_fn=mae.apply, params=params, tx=tx)\n",
        "\n",
        "    batch_size = 128\n",
        "    num_epochs = 100\n",
        "    steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "    losses = []  # List to store loss values\n",
        "\n",
        "    # Select a fixed set of test images for visualization\n",
        "    test_sample_idx = np.random.choice(len(x_test), 4, replace=False)\n",
        "    test_sample = x_test[test_sample_idx]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for step in range(steps_per_epoch):\n",
        "            batch_idx = np.random.choice(len(x_train), batch_size)\n",
        "            batch = x_train[batch_idx]\n",
        "            rng, step_rng = jax.random.split(rng)\n",
        "            state, loss, rng = train_step(state, batch, step_rng)\n",
        "            total_loss += loss\n",
        "\n",
        "        avg_loss = total_loss / steps_per_epoch\n",
        "        losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Visualize reconstructions every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            rng, eval_rng = jax.random.split(rng)\n",
        "            reconstructed, mask = evaluate_reconstruction(state, test_sample, eval_rng)\n",
        "            visualize_reconstructions(test_sample, reconstructed, mask, epoch + 1)\n",
        "\n",
        "    print(\"Pretraining complete!\")\n",
        "\n",
        "    # Plot the loss curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, num_epochs + 1), losses)\n",
        "    plt.title('Training Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Average Loss')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"loss_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjlUGAMVt2Mk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}